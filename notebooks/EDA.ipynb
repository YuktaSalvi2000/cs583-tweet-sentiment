{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QES802c1c78S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from datasets import Dataset\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5MFGJJneDd6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        ")\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAfiLMgNsXEX"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "#Please : i renamed the dfs to add clarity\n",
        "obama_df = pd.read_excel('/content/training-Obama-Romney-tweets.xlsx', sheet_name='Obama')\n",
        "romney_df = pd.read_excel('/content/training-Obama-Romney-tweets.xlsx', sheet_name='Romney')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeF6C3Kdgqiq"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def cleaning_and_processing(df):\n",
        "  #Drof the first completely empty column\n",
        "  df = df.drop(df.columns[0], axis = 1)\n",
        "  #rename columns\n",
        "  df = df.rename(columns={\n",
        "      'date' : 'date',\n",
        "      'time' : 'time',\n",
        "      'Anootated tweet': 'tweet',\n",
        "      'Unnamed: 4': 'label',\n",
        "      'Unnamed: 5': 'your_label'\n",
        "  })\n",
        "  #remove tags from tweet column -- Please : maybe remove it, we're already doing that in the main tweet cleaning fx?\n",
        "  df['tweet'] = df['tweet'].str.replace(r'<[^>]+>', '', regex=True)\n",
        "  #drop second empty/useless row\n",
        "  df = df.drop(index=1).reset_index(drop=True)\n",
        "  #Drop your label for now, its useless\n",
        "  df = df.drop(columns=['your_label'])\n",
        "  #convert date and time\n",
        "  '''\n",
        "  these are raising a lot of errors ad we don't even need it so cmt out\n",
        "  df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date\n",
        "  df['time'] = pd.to_datetime(df['time'], errors='coerce').dt.time\n",
        "  '''\n",
        "  df['label'] = df['label'].replace(2, 0)\n",
        "  df = df[df['label'].isin([-1, 0, 1])].reset_index(drop=True)\n",
        "  df[\"clean_tweet\"] = df[\"tweet\"].apply(clean_tweet)\n",
        "  df = df.drop(columns=['tweet'])\n",
        "  df = df.rename(columns={'clean_tweet': 'tweet'})\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x65VCHmkhGZH"
      },
      "outputs": [],
      "source": [
        "# will be changed with respect to test data format\n",
        "def cleaning_and_processing_testdata(df):\n",
        "  #Drof the first completely empty column\n",
        "  df = df.drop(df.columns[0], axis = 1)\n",
        "  #rename columns\n",
        "  df = df.rename(columns={\n",
        "      'date' : 'date',\n",
        "      'time' : 'time',\n",
        "      'Anootated tweet': 'tweet',\n",
        "      'Unnamed: 4': 'label',\n",
        "      'Unnamed: 5': 'your_label'\n",
        "  })\n",
        "  #remove tags from tweet column -- Please : maybe remove it, we're already doing that in the main tweet cleaning fx?\n",
        "  df['tweet'] = df['tweet'].str.replace(r'<[^>]+>', '', regex=True)\n",
        "  #drop second empty/useless row\n",
        "  df = df.drop(index=1).reset_index(drop=True)\n",
        "  #Drop your label for now, its useless\n",
        "  df = df.drop(columns=['your_label'])\n",
        "  #convert date and time\n",
        "  '''\n",
        "  these are raising a lot of errors ad we don't even need it so cmt out\n",
        "  df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date\n",
        "  df['time'] = pd.to_datetime(df['time'], errors='coerce').dt.time\n",
        "  '''\n",
        "\n",
        "  df = df[df['label'].isin([-1, 0, 1])].reset_index(drop=True)\n",
        "  df[\"clean_tweet\"] = df[\"tweet\"].apply(clean_tweet)\n",
        "  df = df.drop(columns=['tweet'])\n",
        "  df = df.rename(columns={'clean_tweet': 'tweet'})\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Y617uyokKb"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def clean_tweet(text):\n",
        "    if pd.isna(text):\n",
        "        #return text #Please : this might return null or nan so i changed it\n",
        "        return ''\n",
        "    #convert everything to string\n",
        "    text = str(text)\n",
        "    #lowercase everything\n",
        "    text = text.lower()\n",
        "    # remove @handles even if stuck to other text\n",
        "    text = re.sub(r'@\\w+', '', text) #Please : added \\w+ to remove full mention, not just @\n",
        "    # remove http, https, or www links even if glued to other text\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    # remove HTML-like tags (<a>, </e>, etc.)\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # remove hashtags symbol but keep the word (optional)\n",
        "    text = re.sub(r'#', '', text)\n",
        "    # remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    #remove punctuation except letters numbers spaces\n",
        "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5FwLUYxpli3"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "#apply the cleaning to the data\n",
        "obama_df = cleaning_and_processing(obama_df)\n",
        "romney_df = cleaning_and_processing(romney_df)"
      ]
    }
  ]
}
